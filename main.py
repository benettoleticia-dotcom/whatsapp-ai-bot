import os
import asyncio
import random
import logging
import json
import re
from datetime import datetime
from fastapi import FastAPI, Request
from fastapi.responses import HTMLResponse
import httpx
from openai import OpenAI

# ConfiguraÃ§Ã£o de logging compatÃ­vel com Render
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("ana_bot")

app = FastAPI()

# ConfiguraÃ§Ãµes (usando variÃ¡veis de ambiente do Render)
MAYTAPI_PRODUCT_ID = os.getenv("MAYTAPI_PRODUCT_ID", "f38c3b76-29d1-4f85-ab4e-c3c911b7116c")
MAYTAPI_PHONE_ID = os.getenv("MAYTAPI_PHONE_ID", "107677")
MAYTAPI_TOKEN = os.getenv("MAYTAPI_TOKEN", "c9510ef0-09e6-4780-bb6a-72b137811069")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "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")

# Inicializa OpenAI
try:
    client = OpenAI(api_key=OPENAI_API_KEY)
    logger.info("âœ… OpenAI client inicializado")
except Exception as e:
    logger.error(f"âŒ Erro ao inicializar OpenAI: {e}")

# Sistema de memÃ³ria SIMPLIFICADO (sem SQLite para evitar problemas no Render)
class SimpleMemorySystem:
    def __init__(self):
        self.user_data = {}  # MemÃ³ria em RAM (resetarÃ¡ com restart, mas funcional)
        self.conversations = {}
        logger.info("âœ… Sistema de memÃ³ria simples inicializado")
    
    def get_user_profile(self, user_id):
        return self.user_data.get(user_id, {
            'user_id': user_id,
            'name': '',
            'location': '',
            'city': '',
            'messages_count': 0,
            'last_interaction': datetime.now(),
            'converted': False,
            'conversion_stage': 'initial'
        })
    
    def update_user_profile(self, user_id, **kwargs):
        if user_id not in self.user_data:
            self.user_data[user_id] = self.get_user_profile(user_id)
        
        # Atualiza campos
        for key, value in kwargs.items():
            if value is not None:
                self.user_data[user_id][key] = value
        
        self.user_data[user_id]['last_interaction'] = datetime.now()
        logger.info(f"ğŸ‘¤ Perfil atualizado: {user_id}")
    
    def log_conversation(self, user_id, user_message, ai_response, message_type, stage):
        if user_id not in self.conversations:
            self.conversations[user_id] = []
        
        self.conversations[user_id].append({
            'user_message': user_message,
            'ai_response': ai_response,
            'message_type': message_type,
            'stage': stage,
            'timestamp': datetime.now()
        })
        
        # MantÃ©m apenas Ãºltimas 50 conversas por usuÃ¡rio (economia de memÃ³ria)
        if len(self.conversations[user_id]) > 50:
            self.conversations[user_id] = self.conversations[user_id][-50:]

# InstÃ¢ncia global da memÃ³ria
memory = SimpleMemorySystem()
user_histories = {}  # Cache das conversas

class RenderCompatibleBot:
    def __init__(self):
        self.max_context = 8
        
        # Cidades portuguesas
        self.portuguese_cities = {
            'lisboa': 'Lisboa', 'porto': 'Porto', 'coimbra': 'Coimbra', 'braga': 'Braga',
            'aveiro': 'Aveiro', 'faro': 'Faro', 'cascais': 'Cascais', 'felgueiras': 'Felgueiras',
            'leiria': 'Leiria', 'setubal': 'SetÃºbal', 'vila nova de gaia': 'Vila Nova de Gaia'
        }
        
        logger.info("âœ… Bot inicializado com compatibilidade Render")
    
    def get_current_time_period(self):
        """Determina perÃ­odo do dia"""
        current_hour = datetime.now().hour
        
        if 6 <= current_hour < 12:
            return 'morning'
        elif 12 <= current_hour < 18:
            return 'afternoon'  
        elif 18 <= current_hour < 22:
            return 'evening'
        else:
            return 'night'
    
    def extract_location_info(self, message):
        """Extrai localizaÃ§Ã£o"""
        message_lower = message.lower()
        
        if 'portugal' in message_lower:
            return {'type': 'country', 'location': 'Portugal', 'city': None}
        
        for city_key, city_name in self.portuguese_cities.items():
            if city_key in message_lower:
                return {'type': 'city', 'location': city_name, 'city': city_name}
        
        return None
    
    def analyze_conversation_context(self, user_id, message):
        """AnÃ¡lise contextual simplificada"""
        profile = memory.get_user_profile(user_id)
        history = user_histories.get(user_id, [])
        
        context = {
            'already_asked_location': False,
            'knows_location': bool(profile.get('city')),
            'location_info': self.extract_location_info(message),
            'messages_count': len(history),
            'stage': profile.get('conversion_stage', 'initial'),
            'time_period': self.get_current_time_period()
        }
        
        # Verifica se jÃ¡ perguntou localizaÃ§Ã£o
        for msg in history:
            if 'cidade' in msg.get('content', '').lower():
                context['already_asked_location'] = True
                break
        
        return context
    
    def determine_conversion_stage(self, user_id, message, context):
        """Determina estÃ¡gio da conversa"""
        message_lower = message.lower()
        
        interest_keywords = ['interesse', 'quero', 'comprar', 'valores', 'preÃ§o', 'quanto', 'cliente', 'plataforma']
        service_keywords = ['sexo', 'sair', 'encontrar', 'transar', 'serviÃ§os']
        closing_keywords = ['sim', 'vamos', 'ok', 'feito', 'pago']
        
        if any(keyword in message_lower for keyword in closing_keywords) and context['stage'] in ['pricing', 'explanation']:
            return 'closing'
        elif any(keyword in message_lower for keyword in interest_keywords):
            return 'pricing'
        elif any(keyword in message_lower for keyword in service_keywords):
            return 'explanation'
        elif context['messages_count'] <= 2:
            return 'initial'
        else:
            return 'qualification'
    
    def build_natural_prompt(self, user_id, message, context, message_type):
        """Prompt otimizado para Render"""
        
        profile = memory.get_user_profile(user_id)
        user_name = profile.get('name', 'cliente') if profile else 'cliente'
        user_location = profile.get('city') if profile else None
        
        ai_location = user_location if user_location else "Porto"
        if context['location_info'] and context['location_info']['type'] == 'city':
            ai_location = context['location_info']['city']
        
        # Prompt mais conciso para evitar problemas de token no Render
        time_mood = {
            'morning': 'energÃ©tica e carinhosa â˜€ï¸',
            'afternoon': 'relaxada e conversadora ğŸ˜Š', 
            'evening': 'sedutora e direta ğŸŒ™',
            'night': 'Ã­ntima e provocante ğŸ˜˜'
        }
        
        mood = time_mood.get(context['time_period'], 'natural')
        
        # Contexto para fotos
        photo_context = ""
        if message_type in ["image", "photo"]:
            photo_context = "Cliente enviou FOTO! Reage com entusiasmo: 'Que giro! ğŸ˜' ou similar."
        
        prompt = f"""Ã‰s Ana, portuguesa de {ai_location}. Trabalhas com conteÃºdo adulto.

AGORA: {mood}
SITUAÃ‡ÃƒO: Cliente {user_name} | Msg #{context['messages_count']+1} | {context['stage']}
{photo_context}

COMO RESPONDER:
â€¢ PortuguÃªs de Portugal natural
â€¢ MÃ¡ximo 2 linhas por mensagem  
â€¢ Varia respostas, nunca repete
â€¢ Usa emojis quando apropriado

REGRAS:
â†’ Primeira vez + nÃ£o sabe cidade = "De onde me falas?"
â†’ Pergunta serviÃ§os = "SÃ³ saio com meus clientes das plataformas"  
â†’ Interesse preÃ§o = "â‚¬19,90 pagamento Ãºnico, baratinho"
â†’ Comprar = https://buy.stripe.com/14k4iR16VdNk43mfZ5

EXEMPLOS:
- "Oi! De onde me falas?" (primeira vez)
- "Que giro essa foto! ğŸ˜" (recebeu foto)
- "â‚¬19,90, bem baratinho para selecionar quem quer mesmo"
- "Kkk nÃ£o dÃ¡ para sair com qualquer um nÃ© ğŸ˜‰"

Responde natural como WhatsApp real:"""
        
        return prompt

    async def split_message(self, message):
        """Quebra mensagens longas"""
        if len(message) <= 100:
            return [message]
        
        # Quebra simples por frases
        sentences = re.split(r'[.!?]\s+', message)
        messages = []
        current = ""
        
        for sentence in sentences:
            if len(current + sentence) <= 100:
                current += sentence + ". "
            else:
                if current:
                    messages.append(current.strip())
                current = sentence + ". "
        
        if current:
            messages.append(current.strip())
        
        return messages if messages else [message]

    async def get_natural_response(self, user_id: str, user_message: str, message_type: str = "text"):
        """Gera resposta natural (compatÃ­vel com Render)"""
        try:
            logger.info(f"ğŸ¤– Processando: {user_id[:8]}... | {message_type} | {user_message[:50]}...")
            
            # Analisa contexto
            context = self.analyze_conversation_context(user_id, user_message)
            
            # Determina estÃ¡gio
            stage = self.determine_conversion_stage(user_id, user_message, context)
            
            # Atualiza histÃ³rico
            if user_id not in user_histories:
                user_histories[user_id] = []
            
            user_histories[user_id].append({"role": "user", "content": user_message})
            user_histories[user_id] = user_histories[user_id][-self.max_context:]
            
            # Atualiza localizaÃ§Ã£o se detectada
            if context['location_info']:
                location_data = context['location_info']
                if location_data['type'] == 'city':
                    memory.update_user_profile(
                        user_id, 
                        city=location_data['city'],
                        location=location_data['location'],
                        conversion_stage=stage,
                        messages_count=len(user_histories[user_id])
                    )
            
            # ConstrÃ³i prompt
            system_prompt = {
                "role": "system",
                "content": self.build_natural_prompt(user_id, user_message, context, message_type)
            }
            
            # Processa mensagem baseada no tipo
            processed_message = user_message
            if message_type == "audio":
                processed_message = f"[Ãudio] {user_message}"
            elif message_type in ["image", "photo"]:
                if user_message.strip():
                    processed_message = f"[Foto com legenda: {user_message}]"
                else:
                    processed_message = "[Enviou uma foto]"
            elif message_type == "video":
                processed_message = f"[VÃ­deo] {user_message if user_message.strip() else 'sem legenda'}"
            
            # Gera resposta com tratamento de erro
            try:
                response = client.chat.completions.create(
                    model="gpt-4o-mini",  # Modelo mais estÃ¡vel para Render
                    messages=[system_prompt] + user_histories[user_id],
                    temperature=0.9,
                    max_tokens=300,
                    frequency_penalty=0.6,
                    presence_penalty=0.4
                )
                
                reply = response.choices[0].message.content.strip()
                
            except Exception as e:
                logger.error(f"âŒ Erro OpenAI: {e}")
                # Fallback para erro de API
                replies = [
                    "Oi! Tive um probleminha tÃ©cnico ğŸ˜…",
                    "Desculpa, pode repetir?", 
                    "Falha na conexÃ£o, tenta de novo"
                ]
                reply = random.choice(replies)
            
            # Quebra mensagem se necessÃ¡rio
            messages = await self.split_message(reply)
            
            # Adiciona ao histÃ³rico
            user_histories[user_id].append({"role": "assistant", "content": reply})
            
            # Salva conversa
            memory.log_conversation(user_id, user_message, reply, message_type, stage)
            
            # Log de conversÃ£o
            if any("stripe.com" in msg for msg in messages):
                logger.info(f"ğŸ’° CONVERSÃƒO: Link enviado para {user_id[:8]}...")
            
            logger.info(f"âœ… Resposta gerada: {len(messages)} mensagens")
            return messages

        except Exception as e:
            logger.error(f"ğŸ’¥ Erro geral: {e}")
            return ["Oi querido, tive um problema. Podes tentar de novo? ğŸ˜Š"]

    async def send_whatsapp_message(self, to: str, message: str):
        """Envia mensagem via Maytapi (com tratamento de erro)"""
        try:
            url = f"https://api.maytapi.com/api/{MAYTAPI_PRODUCT_ID}/{MAYTAPI_PHONE_ID}/sendMessage"
            
            headers = {
                "Content-Type": "application/json", 
                "x-maytapi-key": MAYTAPI_TOKEN
            }
            
            clean_phone = to.replace("@c.us", "").replace("+", "").replace("-", "").replace(" ", "")
            
            payload = {
                "to_number": clean_phone,
                "type": "text",
                "message": message
            }

            async with httpx.AsyncClient(timeout=30.0) as client_http:
                response = await client_http.post(url, headers=headers, json=payload)
                
                if response.status_code == 200:
                    logger.info(f"âœ… Enviado: {message[:40]}...")
                    return True
                else:
                    logger.error(f"âŒ Erro Maytapi: {response.status_code}")
                    return False
                    
        except Exception as e:
            logger.error(f"âŒ ExceÃ§Ã£o envio: {e}")
            return False

    async def send_multiple_messages(self, phone: str, messages: list):
        """Envia mÃºltiplas mensagens com delays"""
        for i, message in enumerate(messages):
            if i > 0:
                delay = random.uniform(2, 6)  # Delay entre mensagens
                await asyncio.sleep(delay)
            
            success = await self.send_whatsapp_message(phone, message)
            if not success:
                logger.error(f"âŒ Falha na mensagem {i+1}/{len(messages)}")
                break
            
            await asyncio.sleep(1)  # Pausa mÃ­nima entre envios

    async def transcribe_audio(self, audio_url):
        """Transcreve Ã¡udio (com fallback)"""
        try:
            async with httpx.AsyncClient(timeout=60.0) as client_http:
                audio_response = await client_http.get(audio_url)
                if audio_response.status_code == 200:
                    with open("temp_audio.ogg", "wb") as f:
                        f.write(audio_response.content)
                    
                    with open("temp_audio.ogg", "rb") as audio_file:
                        transcription = client.audio.transcriptions.create(
                            model="whisper-1",
                            file=audio_file
                        )
                    
                    os.remove("temp_audio.ogg")
                    return transcription.text
            
            return "NÃ£o consegui processar o Ã¡udio"
            
        except Exception as e:
            logger.error(f"âŒ Erro transcriÃ§Ã£o: {e}")
            return "Ãudio recebido mas nÃ£o consegui ouvir"

# InstÃ¢ncia global do bot
bot = RenderCompatibleBot()

@app.post("/webhook")
async def webhook_handler(request: Request):
    """Webhook handler compatÃ­vel com Render"""
    try:
        # Log da requisiÃ§Ã£o
        logger.info("ğŸ“¨ Webhook recebido")
        
        data = await request.json()
        
        user = data.get("user", {})
        phone = user.get("phone")
        user_name = user.get("name", "")
        message_data = data.get("message", {})

        # ValidaÃ§Ãµes
        if not phone or not message_data or message_data.get("fromMe", False):
            logger.info("â­ï¸ Mensagem ignorada")
            return {"status": "ignored"}

        message_type = message_data.get("type", "text")
        user_message = ""
        
        # Processa diferentes tipos
        if message_type == "text":
            user_message = message_data.get("text", "")
        elif message_type == "audio":
            audio_url = message_data.get("url", "")
            if audio_url:
                user_message = await bot.transcribe_audio(audio_url)
                logger.info(f"ğŸµ Ãudio: {user_message[:50]}...")
            else:
                user_message = "Recebi teu Ã¡udio"
        elif message_type in ["image", "video", "photo"]:
            caption = message_data.get("caption", "")
            user_message = caption
            logger.info(f"ğŸ“¸ {message_type.capitalize()}: {caption or 'sem legenda'}")
        else:
            logger.info(f"ğŸ“‹ Tipo nÃ£o suportado: {message_type}")
            return {"status": "ignored"}

        # Log principal
        logger.info(f"ğŸ‘¤ {user_name[:20]} | {phone[-8:]} | [{message_type}] {user_message[:100]}")

        # Delay inicial
        initial_delay = random.randint(3, 10)
        logger.info(f"â° Delay: {initial_delay}s")
        await asyncio.sleep(initial_delay)
        
        # Gera resposta
        messages = await bot.get_natural_response(phone, user_message, message_type)
        
        # Envia mensagens
        await bot.send_multiple_messages(phone, messages)
        
        logger.info(f"âœ… Conversa processada com sucesso")
        return {"status": "success", "messages_sent": len(messages)}

    except Exception as e:
        logger.error(f"ğŸ’¥ ERRO CRÃTICO: {e}")
        return {"status": "error", "error": str(e)}

@app.get("/")
async def health_check():
    """Health check para Render"""
    try:
        # Testa OpenAI
        test_response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": "test"}],
            max_tokens=5
        )
        openai_status = "âœ… OK"
    except:
        openai_status = "âŒ ERRO"
    
    # Stats bÃ¡sicas
    total_users = len(memory.user_data)
    total_conversations = sum(len(convs) for convs in memory.conversations.values())
    
    html = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>ğŸ¤– Ana Bot - Render Deploy</title>
        <meta charset="utf-8">
        <style>
            body {{font-family: Arial; margin: 30px; background: #f0f8ff;}}
            .card {{background: white; padding: 20px; margin: 15px 0; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);}}
            .status {{font-size: 18px; margin: 10px 0;}}
            .success {{color: #28a745;}}
            .error {{color: #dc3545;}}
            .info {{color: #17a2b8;}}
        </style>
    </head>
    <body>
        <h1>ğŸ¤– Ana Bot - Status Deploy</h1>
        
        <div class="card">
            <h2>ğŸ“Š Status do Sistema</h2>
            <div class="status">OpenAI API: <span class="{('success' if 'âœ…' in openai_status else 'error')}">{openai_status}</span></div>
            <div class="status">MemÃ³ria: <span class="success">âœ… Ativa</span></div>
            <div class="status">Webhook: <span class="success">âœ… Funcional</span></div>
            <div class="status">Deploy: <span class="success">âœ… Render OK</span></div>
        </div>
        
        <div class="card">
            <h2>ğŸ“ˆ EstatÃ­sticas</h2>
            <p><strong>UsuÃ¡rios:</strong> {total_users}</p>
            <p><strong>Conversas:</strong> {total_conversations}</p>
            <p><strong>Tempo Online:</strong> {datetime.now().strftime('%H:%M:%S')}</p>
            <p><strong>Servidor:</strong> Render Cloud</p>
        </div>
        
        <div class="card">
            <h2>âš™ï¸ ConfiguraÃ§Ãµes</h2>
            <p>âœ… MemÃ³ria em RAM (nÃ£o precisa SQLite)</p>
            <p>âœ… Logs detalhados</p>
            <p>âœ… Tratamento de erros</p>
            <p>âœ… Timeouts configurados</p>
            <p>âœ… Fallbacks implementados</p>
        </div>
        
        <div class="card">
            <h2>ğŸ¯ Funcionalidades</h2>
            <p>ğŸ¤– Respostas naturais GPT-4</p>
            <p>ğŸ“¸ Suporte a fotos e vÃ­deos</p>
            <p>ğŸµ TranscriÃ§Ã£o de Ã¡udio</p>
            <p>ğŸ’¬ MÃºltiplas mensagens</p>
            <p>â° Delays humanos</p>
            <p>ğŸ’° Sistema de conversÃ£o</p>
        </div>
    </body>
    </html>
    """
    
    return HTMLResponse(html)

@app.get("/health")
async def health():
    """Health endpoint simples para Render"""
    return {"status": "healthy", "timestamp": datetime.now()}

if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 10000))
    logger.info(f"ğŸš€ Ana Bot iniciando na porta {port}")
    logger.info("âœ… VersÃ£o compatÃ­vel com Render")
    logger.info("âœ… MemÃ³ria em RAM")
    logger.info("âœ… Tratamento de erros robusto") 
    uvicorn.run(app, host="0.0.0.0", port=port)
