import os
import asyncio
import random
import logging
import json
import re
from datetime import datetime
from fastapi import FastAPI, Request
from fastapi.responses import HTMLResponse
import httpx
from openai import OpenAI

# Configura√ß√£o de logging compat√≠vel com Render
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("ana_bot")

app = FastAPI()

# Configura√ß√µes (usando vari√°veis de ambiente do Render)
MAYTAPI_PRODUCT_ID = os.getenv("MAYTAPI_PRODUCT_ID", "f38c3b76-29d1-4f85-ab4e-c3c911b7116c")
MAYTAPI_PHONE_ID = os.getenv("MAYTAPI_PHONE_ID", "107677")
MAYTAPI_TOKEN = os.getenv("MAYTAPI_TOKEN", "c9510ef0-09e6-4780-bb6a-72b137811069")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "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")

# Inicializa OpenAI
try:
    client = OpenAI(api_key=OPENAI_API_KEY)
    logger.info("‚úÖ OpenAI client inicializado")
except Exception as e:
    logger.error(f"‚ùå Erro ao inicializar OpenAI: {e}")

# Sistema de mem√≥ria SIMPLIFICADO (sem SQLite para evitar problemas no Render)
class SimpleMemorySystem:
    def __init__(self):
        self.user_data = {}  # Mem√≥ria em RAM (resetar√° com restart, mas funcional)
        self.conversations = {}
        logger.info("‚úÖ Sistema de mem√≥ria simples inicializado")
    
    def get_user_profile(self, user_id):
        return self.user_data.get(user_id, {
            'user_id': user_id,
            'name': '',
            'location': '',
            'city': '',
            'messages_count': 0,
            'last_interaction': datetime.now(),
            'converted': False,
            'conversion_stage': 'initial'
        })
    
    def update_user_profile(self, user_id, **kwargs):
        if user_id not in self.user_data:
            self.user_data[user_id] = self.get_user_profile(user_id)
        
        # Atualiza campos
        for key, value in kwargs.items():
            if value is not None:
                self.user_data[user_id][key] = value
        
        self.user_data[user_id]['last_interaction'] = datetime.now()
        logger.info(f"üë§ Perfil atualizado: {user_id}")
    
    def log_conversation(self, user_id, user_message, ai_response, message_type, stage):
        if user_id not in self.conversations:
            self.conversations[user_id] = []
        
        self.conversations[user_id].append({
            'user_message': user_message,
            'ai_response': ai_response,
            'message_type': message_type,
            'stage': stage,
            'timestamp': datetime.now()
        })
        
        # Mant√©m apenas √∫ltimas 50 conversas por usu√°rio (economia de mem√≥ria)
        if len(self.conversations[user_id]) > 50:
            self.conversations[user_id] = self.conversations[user_id][-50:]

# Inst√¢ncia global da mem√≥ria
memory = SimpleMemorySystem()
user_histories = {}  # Cache das conversas

class RenderCompatibleBot:
    def __init__(self):
        self.max_context = 8
        
        # Cidades portuguesas
        self.portuguese_cities = {
            'lisboa': 'Lisboa', 'porto': 'Porto', 'coimbra': 'Coimbra', 'braga': 'Braga',
            'aveiro': 'Aveiro', 'faro': 'Faro', 'cascais': 'Cascais', 'felgueiras': 'Felgueiras',
            'leiria': 'Leiria', 'setubal': 'Set√∫bal', 'vila nova de gaia': 'Vila Nova de Gaia'
        }
        
        logger.info("‚úÖ Bot inicializado com compatibilidade Render")
    
    def get_current_time_period(self):
        """Determina per√≠odo do dia"""
        current_hour = datetime.now().hour
        
        if 6 <= current_hour < 12:
            return 'morning'
        elif 12 <= current_hour < 18:
            return 'afternoon'  
        elif 18 <= current_hour < 22:
            return 'evening'
        else:
            return 'night'
    
    def extract_location_info(self, message):
        """Extrai localiza√ß√£o"""
        message_lower = message.lower()
        
        if 'portugal' in message_lower:
            return {'type': 'country', 'location': 'Portugal', 'city': None}
        
        for city_key, city_name in self.portuguese_cities.items():
            if city_key in message_lower:
                return {'type': 'city', 'location': city_name, 'city': city_name}
        
        return None
    
    def analyze_conversation_context(self, user_id, message):
        """An√°lise contextual simplificada"""
        profile = memory.get_user_profile(user_id)
        history = user_histories.get(user_id, [])
        
        context = {
            'already_asked_location': False,
            'knows_location': bool(profile.get('city')),
            'location_info': self.extract_location_info(message),
            'messages_count': len(history),
            'stage': profile.get('conversion_stage', 'initial'),
            'time_period': self.get_current_time_period()
        }
        
        # Verifica se j√° perguntou localiza√ß√£o
        for msg in history:
            if 'cidade' in msg.get('content', '').lower():
                context['already_asked_location'] = True
                break
        
        return context
    
    def determine_conversion_stage(self, user_id, message, context):
        """Determina est√°gio da conversa"""
        message_lower = message.lower()
        
        interest_keywords = ['interesse', 'quero', 'comprar', 'valores', 'pre√ßo', 'quanto', 'cliente', 'plataforma']
        service_keywords = ['sexo', 'sair', 'encontrar', 'transar', 'servi√ßos']
        closing_keywords = ['sim', 'vamos', 'ok', 'feito', 'pago']
        
        if any(keyword in message_lower for keyword in closing_keywords) and context['stage'] in ['pricing', 'explanation']:
            return 'closing'
        elif any(keyword in message_lower for keyword in interest_keywords):
            return 'pricing'
        elif any(keyword in message_lower for keyword in service_keywords):
            return 'explanation'
        elif context['messages_count'] <= 2:
            return 'initial'
        else:
            return 'qualification'
    
    def build_natural_prompt(self, user_id, message, context, message_type):
        """Prompt otimizado para Render"""
        
        profile = memory.get_user_profile(user_id)
        user_name = profile.get('name', 'cliente') if profile else 'cliente'
        user_location = profile.get('city') if profile else None
        
        ai_location = user_location if user_location else "Porto"
        if context['location_info'] and context['location_info']['type'] == 'city':
            ai_location = context['location_info']['city']
        
        # Prompt mais conciso para evitar problemas de token no Render
        time_mood = {
            'morning': 'energ√©tica e carinhosa ‚òÄÔ∏è',
            'afternoon': 'relaxada e conversadora üòä', 
            'evening': 'sedutora e direta üåô',
            'night': '√≠ntima e provocante üòò'
        }
        
        mood = time_mood.get(context['time_period'], 'natural')
        
        # Contexto para fotos
        photo_context = ""
        if message_type in ["image", "photo"]:
            photo_context = "Cliente enviou FOTO! Reage com entusiasmo: 'Que giro! üòç' ou similar."
        
        prompt = f"""√âs Ana, portuguesa de {ai_location}. Trabalhas com conte√∫do adulto.

AGORA: {mood}
SITUA√á√ÉO: Cliente {user_name} | Msg #{context['messages_count']+1} | {context['stage']}
{photo_context}

COMO RESPONDER:
‚Ä¢ Portugu√™s de Portugal natural
‚Ä¢ M√°ximo 2 linhas por mensagem  
‚Ä¢ Varia respostas, nunca repete
‚Ä¢ Usa emojis quando apropriado

REGRAS:
‚Üí Primeira vez + n√£o sabe cidade = "De onde me falas?"
‚Üí Pergunta servi√ßos = "S√≥ saio com meus clientes das plataformas"  
‚Üí Interesse pre√ßo = "‚Ç¨19,90 pagamento √∫nico, baratinho"
‚Üí Comprar = https://buy.stripe.com/14k4iR16VdNk43mfZ5

EXEMPLOS:
- "Oi! De onde me falas?" (primeira vez)
- "Que giro essa foto! üòç" (recebeu foto)
- "‚Ç¨19,90, bem baratinho para selecionar quem quer mesmo"
- "Kkk n√£o d√° para sair com qualquer um n√© üòâ"

Responde natural como WhatsApp real:"""
        
        return prompt

    async def split_message(self, message):
        """Quebra mensagens longas"""
        if len(message) <= 100:
            return [message]
        
        # Quebra simples por frases
        sentences = re.split(r'[.!?]\s+', message)
        messages = []
        current = ""
        
        for sentence in sentences:
            if len(current + sentence) <= 100:
                current += sentence + ". "
            else:
                if current:
                    messages.append(current.strip())
                current = sentence + ". "
        
        if current:
            messages.append(current.strip())
        
        return messages if messages else [message]

    async def get_natural_response(self, user_id: str, user_message: str, message_type: str = "text"):
        """Gera resposta natural (compat√≠vel com Render)"""
        try:
            logger.info(f"ü§ñ Processando: {user_id[:8]}... | {message_type} | {user_message[:50]}...")
            
            # Analisa contexto
            context = self.analyze_conversation_context(user_id, user_message)
            
            # Determina est√°gio
            stage = self.determine_conversion_stage(user_id, user_message, context)
            
            # Atualiza hist√≥rico
            if user_id not in user_histories:
                user_histories[user_id] = []
            
            user_histories[user_id].append({"role": "user", "content": user_message})
            user_histories[user_id] = user_histories[user_id][-self.max_context:]
            
            # Atualiza localiza√ß√£o se detectada
            if context['location_info']:
                location_data = context['location_info']
                if location_data['type'] == 'city':
                    memory.update_user_profile(
                        user_id, 
                        city=location_data['city'],
                        location=location_data['location'],
                        conversion_stage=stage,
                        messages_count=len(user_histories[user_id])
                    )
            
            # Constr√≥i prompt
            system_prompt = {
                "role": "system",
                "content": self.build_natural_prompt(user_id, user_message, context, message_type)
            }
            
            # Processa mensagem baseada no tipo
            processed_message = user_message
            if message_type == "audio":
                processed_message = f"[√Åudio] {user_message}"
            elif message_type in ["image", "photo"]:
                if user_message.strip():
                    processed_message = f"[Foto com legenda: {user_message}]"
                else:
                    processed_message = "[Enviou uma foto]"
            elif message_type == "video":
                processed_message = f"[V√≠deo] {user_message if user_message.strip() else 'sem legenda'}"
            
            # Gera resposta com tratamento de erro
            try:
                response = client.chat.completions.create(
                    model="gpt-4o-mini",  # Modelo mais est√°vel para Render
                    messages=[system_prompt] + user_histories[user_id],
                    temperature=0.9,
                    max_tokens=300,
                    frequency_penalty=0.6,
                    presence_penalty=0.4
                )
                
                reply = response.choices[0].message.content.strip()
                
            except Exception as e:
                logger.error(f"‚ùå Erro OpenAI: {e}")
                # Fallback para erro de API
                replies = [
                    "Oi! Tive um probleminha t√©cnico üòÖ",
                    "Desculpa, pode repetir?", 
                    "Falha na conex√£o, tenta de novo"
                ]
                reply = random.choice(replies)
            
            # Quebra mensagem se necess√°rio
            messages = await self.split_message(reply)
            
            # Adiciona ao hist√≥rico
            user_histories[user_id].append({"role": "assistant", "content": reply})
            
            # Salva conversa
            memory.log_conversation(user_id, user_message, reply, message_type, stage)
            
            # Log de convers√£o
            if any("stripe.com" in msg for msg in messages):
                logger.info(f"üí∞ CONVERS√ÉO: Link enviado para {user_id[:8]}...")
            
            logger.info(f"‚úÖ Resposta gerada: {len(messages)} mensagens")
            return messages

        except Exception as e:
            logger.error(f"üí• Erro geral: {e}")
            return ["Oi querido, tive um problema. Podes tentar de novo? üòä"]

    async def send_whatsapp_message(self, to: str, message: str):
        """Envia mensagem via Maytapi (com tratamento de erro)"""
        try:
            url = f"https://api.maytapi.com/api/{MAYTAPI_PRODUCT_ID}/{MAYTAPI_PHONE_ID}/sendMessage"
            
            headers = {
                "Content-Type": "application/json", 
                "x-maytapi-key": MAYTAPI_TOKEN
            }
            
            clean_phone = to.replace("@c.us", "").replace("+", "").replace("-", "").replace(" ", "")
            
            payload = {
                "to_number": clean_phone,
                "type": "text",
                "message": message
            }

            async with httpx.AsyncClient(timeout=30.0) as client_http:
                response = await client_http.post(url, headers=headers, json=payload)
                
                if response.status_code == 200:
                    logger.info(f"‚úÖ Enviado: {message[:40]}...")
                    return True
                else:
                    logger.error(f"‚ùå Erro Maytapi: {response.status_code}")
                    return False
                    
        except Exception as e:
            logger.error(f"‚ùå Exce√ß√£o envio: {e}")
            return False

    async def send_multiple_messages(self, phone: str, messages: list):
        """Envia m√∫ltiplas mensagens com delays"""
        for i, message in enumerate(messages):
            if i > 0:
                delay = random.uniform(2, 6)  # Delay entre mensagens
                await asyncio.sleep(delay)
            
            success = await self.send_whatsapp_message(phone, message)
            if not success:
                logger.error(f"‚ùå Falha na mensagem {i+1}/{len(messages)}")
                break
            
            await asyncio.sleep(1)  # Pausa m√≠nima entre envios

    async def transcribe_audio(self, audio_url):
        """Transcreve √°udio (com fallback)"""
        try:
            async with httpx.AsyncClient(timeout=60.0) as client_http:
                audio_response = await client_http.get(audio_url)
                if audio_response.status_code == 200:
                    with open("temp_audio.ogg", "wb") as f:
                        f.write(audio_response.content)
                    
                    with open("temp_audio.ogg", "rb") as audio_file:
                        transcription = client.audio.transcriptions.create(
                            model="whisper-1",
                            file=audio_file
                        )
                    
                    os.remove("temp_audio.ogg")
                    return transcription.text
            
            return "N√£o consegui processar o √°udio"
            
        except Exception as e:
            logger.error(f"‚ùå Erro transcri√ß√£o: {e}")
            return "√Åudio recebido mas n√£o consegui ouvir"

# Inst√¢ncia global do bot
bot = RenderCompatibleBot()

@app.post("/webhook")
async def webhook_handler(request: Request):
    """Webhook handler compat√≠vel com Render"""
    try:
        # Log da requisi√ß√£o
        logger.info("üì® Webhook recebido")
        
        data = await request.json()
        
        user = data.get("user", {})
        phone = user.get("phone")
        user_name = user.get("name", "")
        message_data = data.get("message", {})

        # Valida√ß√µes
        if not phone or not message_data or message_data.get("fromMe", False):
            logger.info("‚è≠Ô∏è Mensagem ignorada")
            return {"status": "ignored"}

        message_type = message_data.get("type", "text")
        user_message = ""
        
        # Processa diferentes tipos
        if message_type == "text":
            user_message = message_data.get("text", "")
        elif message_type == "audio":
            audio_url = message_data.get("url", "")
            if audio_url:
                user_message = await bot.transcribe_audio(audio_url)
                logger.info(f"üéµ √Åudio: {user_message[:50]}...")
            else:
                user_message = "Recebi teu √°udio"
        elif message_type in ["image", "video", "photo"]:
            caption = message_data.get("caption", "")
            user_message = caption
            logger.info(f"üì∏ {message_type.capitalize()}: {caption or 'sem legenda'}")
        else:
            logger.info(f"üìã Tipo n√£o suportado: {message_type}")
            return {"status": "ignored"}

        # Log principal
        logger.info(f"üë§ {user_name[:20]} | {phone[-8:]} | [{message_type}] {user_message[:100]}")

        # Delay inicial
        initial_delay = random.randint(3, 10)
        logger.info(f"‚è∞ Delay: {initial_delay}s")
        await asyncio.sleep(initial_delay)
        
        # Gera resposta
        messages = await bot.get_natural_response(phone, user_message, message_type)
        
        # Envia mensagens
        await bot.send_multiple_messages(phone, messages)
        
        logger.info(f"‚úÖ Conversa processada com sucesso")
        return {"status": "success", "messages_sent": len(messages)}

    except Exception as e:
        logger.error(f"üí• ERRO CR√çTICO: {e}")
        return {"status": "error", "error": str(e)}

@app.get("/")
async def health_check():
    """Health check para Render"""
    try:
        # Testa OpenAI
        test_response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": "test"}],
            max_tokens=5
        )
        openai_status = "‚úÖ OK"
    except:
        openai_status = "‚ùå ERRO"
    
    # Stats b√°sicas
    total_users = len(memory.user_data)
    total_conversations = sum(len(convs) for convs in memory.conversations.values())
    
    html = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>ü§ñ Ana Bot - Render Deploy</title>
        <meta charset="utf-8">
        <style>
            body {{font-family: Arial; margin: 30px; background: #f0f8ff;}}
            .card {{background: white; padding: 20px; margin: 15px 0; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);}}
            .status {{font-size: 18px; margin: 10px 0;}}
            .success {{color: #28a745;}}
            .error {{color: #dc3545;}}
            .info {{color: #17a2b8;}}
        </style>
    </head>
    <body>
        <h1>ü§ñ Ana Bot - Status Deploy</h1>
        
        <div class="card">
            <h2>üìä Status do Sistema</h2>
            <div class="status">OpenAI API: <span class="{('success' if '‚úÖ' in openai_status else 'error')}">{openai_status}</span></div>
            <div class="status">Mem√≥ria: <span class="success">‚úÖ Ativa</span></div>
            <div class="status">Webhook: <span class="success">‚úÖ Funcional</span></div>
            <div class="status">Deploy: <span class="success">‚úÖ Render OK</span></div>
        </div>
        
        <div class="card">
            <h2>üìà Estat√≠sticas</h2>
            <p><strong>Usu√°rios:</strong> {total_users}</p>
            <p><strong>Conversas:</strong> {total_conversations}</p>
            <p><strong>Tempo Online:</strong> {datetime.now().strftime('%H:%M:%S')}</p>
            <p><strong>Servidor:</strong> Render Cloud</p>
        </div>
        
        <div class="card">
            <h2>‚öôÔ∏è Configura√ß√µes</h2>
            <p>‚úÖ Mem√≥ria em RAM (n√£o precisa SQLite)</p>
            <p>‚úÖ Logs detalhados</p>
            <p>‚úÖ Tratamento de erros</p>
            <p>‚úÖ Timeouts configurados</p>
            <p>‚úÖ Fallbacks implementados</p>
        </div>
        
        <div class="card">
            <h2>üéØ Funcionalidades</h2>
            <p>ü§ñ Respostas naturais GPT-4</p>
            <p>üì∏ Suporte a fotos e v√≠deos</p>
            <p>üéµ Transcri√ß√£o de √°udio</p>
            <p>üí¨ M√∫ltiplas mensagens</p>
            <p>‚è∞ Delays humanos</p>
            <p>üí∞ Sistema de convers√£o</p>
        </div>
    </body>
    </html>
    """
    
    return HTMLResponse(html)

@app.get("/health")
async def health():
    """Health endpoint simples para Render"""
    return {"status": "healthy", "timestamp": datetime.now()}

if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 10000))
    logger.info(f"üöÄ Ana Bot iniciando na porta {port}")
    logger.info("‚úÖ Vers√£o compat√≠vel com Render")
    logger.info("‚úÖ Mem√≥ria em RAM")
    logger.info("‚úÖ Tratamento de erros robusto") 
    uvicorn.run(app, host="0.0.0.0", port=port)
